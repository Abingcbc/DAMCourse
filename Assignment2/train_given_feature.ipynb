{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from mlxtend.classifier import StackingCVClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn import metrics\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open(\"data/train.csv\") as file:\n",
    "    train = pd.read_csv(file)\n",
    "with open(\"data/valid.csv\") as valid_file:\n",
    "    valid = pd.read_csv(valid_file)\n",
    "with open(\"data/test.csv\") as test_file:\n",
    "    test = pd.read_csv(test_file)\n",
    "with open(\"data/user_vec.csv\") as file:\n",
    "    user_vec = pd.read_csv(file)\n",
    "with open(\"data/aver_review.csv\") as file:\n",
    "    words_count = pd.read_csv(file)\n",
    "with open(\"data/aver_figure.csv\") as file:\n",
    "    figuration = pd.read_csv(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "del train['Unnamed: 0']\n",
    "del valid['Unnamed: 0']\n",
    "del test['Unnamed: 0']\n",
    "del user_vec['Unnamed: 0']\n",
    "del words_count['Unnamed: 0']\n",
    "del figuration['Unnamed: 0']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7200"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_df = pd.merge(user_vec,train,on=\"user_id\",how=\"inner\")\n",
    "X_train_df = pd.merge(words_count,X_train_df,on=\"user_id\",how=\"inner\")\n",
    "X_train_df = pd.merge(figuration,X_train_df,on=\"user_id\",how=\"inner\")\n",
    "X_train_df.dropna(inplace=True)\n",
    "len(X_train_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2399"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_valid_df = pd.merge(user_vec,valid,on=\"user_id\",how=\"inner\")\n",
    "X_valid_df = pd.merge(words_count,X_valid_df,on=\"user_id\",how=\"inner\")\n",
    "X_valid_df = pd.merge(figuration,X_valid_df,on=\"user_id\",how=\"inner\")\n",
    "X_valid_df.dropna(inplace=True)\n",
    "len(X_valid_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2400"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test_df = pd.merge(user_vec,test,on=\"user_id\",how=\"inner\")\n",
    "X_test_df = pd.merge(words_count,X_test_df,on=\"user_id\",how=\"inner\")\n",
    "X_test_df = pd.merge(figuration,X_test_df,on=\"user_id\",how=\"inner\")\n",
    "X_test_df.dropna(inplace=True)\n",
    "len(X_test_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train = X_train_df.iloc[:,1:-1].as_matrix().astype(np.float)\n",
    "y_train = X_train_df['gender'].as_matrix().astype(np.float)\n",
    "X_valid = X_valid_df.iloc[:,1:-1].as_matrix().astype(np.float)\n",
    "y_valid = X_valid_df['gender'].as_matrix().astype(np.float)\n",
    "X_test = X_test_df.iloc[:,1:-1].as_matrix().astype(np.float)\n",
    "y_test = X_test_df['gender'].as_matrix().astype(np.float)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_valid = np.concatenate([X_train,X_valid],axis=0)\n",
    "y_train_valid = np.concatenate([y_train,y_valid],axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr = LogisticRegression()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_and_evaluate(clf, X_train, X_test, y_train, y_test):\n",
    "    clf.fit(X_train, y_train)\n",
    "    \n",
    "    y_pred1 = clf.predict(X_test)\n",
    "    \n",
    "    print(\"Scores on test dataset\")\n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y_test,y_pred1))) \n",
    "    print(\"Precision: \" + str(metrics.precision_score(y_test, y_pred1)))\n",
    "    print(\"Recall: \" + str(metrics.recall_score(y_test, y_pred1)))\n",
    "    print(\"F1: \" + str(metrics.f1_score(y_test,y_pred1)))\n",
    "    \n",
    "    y_pred2 = clf.predict(X_train)\n",
    "    \n",
    "    print(\"Scores on train dataset\")\n",
    "    print(\"Accuracy: \" + str(metrics.accuracy_score(y_train,y_pred2)))\n",
    "    print(\"Precision: \" + str(metrics.precision_score(y_train, y_pred2)))\n",
    "    print(\"Recall: \" + str(metrics.recall_score(y_train, y_pred2)))\n",
    "    print(\"F1: \" + str(metrics.f1_score(y_train,y_pred2)))\n",
    "    \n",
    "    return y_pred1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"lg\", LogisticRegression())\n",
    "])\n",
    "clf2 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"lg\", LogisticRegression())\n",
    "])\n",
    "clf3 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"lg\", LogisticRegression())\n",
    "])\n",
    "clf4 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"lg\", LogisticRegression())\n",
    "])\n",
    "sclf = StackingCVClassifier(classifiers=[clf1,clf2,clf3,clf4],meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.8279166666666666\n",
      "Precision: 0.8451612903225807\n",
      "Recall: 0.9440133037694013\n",
      "F1: 0.8918565069389893\n",
      "Scores on train dataset\n",
      "Accuracy: 0.8319616626731952\n",
      "Precision: 0.8451888094341989\n",
      "Recall: 0.9467397414277684\n",
      "F1: 0.8930867634387221\n"
     ]
    }
   ],
   "source": [
    "y_lr = train_and_evaluate(clf1,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.8279166666666666\n",
      "Precision: 0.8451612903225807\n",
      "Recall: 0.9440133037694013\n",
      "F1: 0.8918565069389893\n",
      "Scores on train dataset\n",
      "Accuracy: 0.8319616626731952\n",
      "Precision: 0.8451888094341989\n",
      "Recall: 0.9467397414277684\n",
      "F1: 0.8930867634387221\n"
     ]
    }
   ],
   "source": [
    "y_lrs = train_and_evaluate(sclf,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"svm\", SVC(kernel='linear'))\n",
    "])\n",
    "clf2 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"svm\", SVC(kernel='linear'))\n",
    "])\n",
    "clf3 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"svm\", SVC(kernel='linear'))\n",
    "])\n",
    "clf4 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"svm\", SVC(kernel='linear'))\n",
    "])\n",
    "sclf = StackingCVClassifier(classifiers=[clf1,clf2,clf3,clf4],meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.8320833333333333\n",
      "Precision: 0.8500749625187406\n",
      "Recall: 0.9429046563192904\n",
      "F1: 0.8940867279894875\n",
      "Scores on train dataset\n",
      "Accuracy: 0.8380039587457027\n",
      "Precision: 0.8510289104910996\n",
      "Recall: 0.9473018549747049\n",
      "F1: 0.8965884152424021\n"
     ]
    }
   ],
   "source": [
    "y_svm = train_and_evaluate(clf1,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.8320833333333333\n",
      "Precision: 0.8500749625187406\n",
      "Recall: 0.9429046563192904\n",
      "F1: 0.8940867279894875\n",
      "Scores on train dataset\n",
      "Accuracy: 0.8380039587457027\n",
      "Precision: 0.8510289104910996\n",
      "Recall: 0.9473018549747049\n",
      "F1: 0.8965884152424021\n"
     ]
    }
   ],
   "source": [
    "y_svms = train_and_evaluate(sclf,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "clf2 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "clf3 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "clf4 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "sclf = StackingCVClassifier(classifiers=[clf1,clf2,clf3,clf4],meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.7666666666666667\n",
      "Precision: 0.8315565031982942\n",
      "Recall: 0.8647450110864745\n",
      "F1: 0.8478260869565217\n",
      "Scores on train dataset\n",
      "Accuracy: 0.994270236482967\n",
      "Precision: 0.9960657580441197\n",
      "Recall: 0.9962057335581788\n",
      "F1: 0.9961357408838614\n"
     ]
    }
   ],
   "source": [
    "y_rf = train_and_evaluate(clf1,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.7920833333333334\n",
      "Precision: 0.8196962273395394\n",
      "Recall: 0.9273835920177383\n",
      "F1: 0.8702210663198958\n",
      "Scores on train dataset\n",
      "Accuracy: 0.9994791124075425\n",
      "Precision: 0.9994381233319286\n",
      "Recall: 0.9998594716132658\n",
      "F1: 0.9996487530734106\n"
     ]
    }
   ],
   "source": [
    "y_rfs = train_and_evaluate(sclf,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"lg\", LogisticRegression())\n",
    "])\n",
    "clf2 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"svm\", SVC(kernel='linear'))\n",
    "])\n",
    "clf3 = Pipeline([\n",
    "    (\"min_max scalar\", MinMaxScaler(feature_range=(0.0,1.0))),\n",
    "    (\"rf\", RandomForestClassifier())\n",
    "])\n",
    "sclf = StackingCVClassifier(classifiers=[clf1,clf2,clf3,clf4],meta_classifier=lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.8308333333333333\n",
      "Precision: 0.846382556987116\n",
      "Recall: 0.9467849223946785\n",
      "F1: 0.8937728937728938\n",
      "Scores on train dataset\n",
      "Accuracy: 0.8410251067819564\n",
      "Precision: 0.8515723270440252\n",
      "Recall: 0.9513771781899943\n",
      "F1: 0.8987123324040887\n"
     ]
    }
   ],
   "source": [
    "y_all = train_and_evaluate(sclf,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.22995388,  0.49086616,  0.67475654, ..., -0.07243913,\n",
       "        -0.31102013, -0.68900824],\n",
       "       [-0.25828434, -0.58213269, -0.11499057, ...,  1.75319954,\n",
       "        -0.13494346,  0.86757924],\n",
       "       [-0.15293   , -0.35438168, -0.49752432, ..., -1.20739211,\n",
       "        -0.99716936, -0.63793663],\n",
       "       ...,\n",
       "       [-0.4754198 , -0.87808691,  1.92107619, ...,  0.40951746,\n",
       "        -0.2000165 ,  0.3843142 ],\n",
       "       [ 0.22201597,  0.46666271,  0.64390704, ...,  0.51796172,\n",
       "         0.57638096, -0.23169261],\n",
       "       [-0.66691896, -0.70442018, -0.54688351, ..., -0.30776511,\n",
       "        -2.17868485, -0.05897368]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "standard = StandardScaler()\n",
    "standard.fit_transform(X_train)\n",
    "standard.fit_transform(X_test)\n",
    "standard.fit_transform(X_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scores on test dataset\n",
      "Accuracy: 0.8254166666666667\n",
      "Precision: 0.8654353562005277\n",
      "Recall: 0.9090909090909091\n",
      "F1: 0.8867261422005949\n",
      "Scores on train dataset\n",
      "Accuracy: 0.8446713199291593\n",
      "Precision: 0.8749500066657779\n",
      "Recall: 0.9222878021360315\n",
      "F1: 0.8979954847095847\n"
     ]
    }
   ],
   "source": [
    "clf = MLPClassifier(hidden_layer_sizes=[20,20,10],max_iter=1000,random_state=33)\n",
    "y_nn = train_and_evaluate(clf,X_train_valid,X_test,y_train_valid,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = pd.DataFrame({'user_id':X_test_df['user_id'],'lr_label':y_lr,'lrs_label':y_lrs,'svm_label':y_svm,\n",
    "                      'svms_label':y_svms,'rf_label':y_rf,'rfs_label':y_rfs,'mix_label':y_all,'nn_label':y_nn,\n",
    "                      'true_label':y_test})\n",
    "result.to_csv('result_given_feature.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
