{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from sklearn.model_selection import train_test_split\n",
    "from keras.layers import LSTM\n",
    "from keras.layers import Dense, Input,Flatten, Dropout, TimeDistributed, RepeatVector\n",
    "from keras.optimizers import Adam\n",
    "from keras import backend as K\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import utm\n",
    "from sklearn.preprocessing import minmax_scale, MinMaxScaler\n",
    "from keras.utils import to_categorical\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch': [], 'epoch': []}\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "def distance_loss(y_pred, y_true):\n",
    "    return K.sqrt(K.mean(K.sum(K.square(y_pred-y_true), axis=-1)))\n",
    "\n",
    "def median_absolute_deviation(y_pred, y_true):\n",
    "    deviation = np.abs(y_pred-y_true)\n",
    "    return np.mean(deviation, axis=0)\n",
    "\n",
    "\n",
    "data = pd.read_csv('trainfix.csv')\n",
    "label = pd.read_csv('label1.csv')['label']\n",
    "X_temp = [\n",
    "    np.concatenate([mr[4:9],mr[9:14],mr[14:19],mr[19:24],mr[24:29],\n",
    "               mr[29:34]]) for mr in data.values\n",
    "]\n",
    "X_temp = np.array(X_temp)\n",
    "y_temp = data[['Latitude','Longitude']].values\n",
    "\n",
    "X = []\n",
    "y = []\n",
    "for t in range(72):\n",
    "    temp = X_temp[data['TrajID'] == t]\n",
    "    temp_y = y_temp[data['TrajID'] == t]\n",
    "    for i in range(len(temp)-5):\n",
    "        X.append(temp[i:i+6])\n",
    "        y.append(temp_y[i:i+6])\n",
    "X = np.array(X)\n",
    "y = np.array(y)\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=33)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(2470,)\n"
     ]
    }
   ],
   "source": [
    "#执行这里会覆盖X_test 出最终结果\n",
    "data_test = pd.read_csv('testfix.csv')\n",
    "TrajID=data_test['TrajID'].values\n",
    "print(TrajID.shape)\n",
    "X_test = [\n",
    "    np.concatenate([mr[4:9],mr[9:14],mr[14:19],mr[19:24],mr[24:29],\n",
    "               mr[29:34]]) for mr in data_test.values\n",
    "]\n",
    "X_test = np.array(X_test)\n",
    "X_final = []\n",
    "traj_id=[]\n",
    "for t in range(72):\n",
    "    temp = X_test[(data_test['TrajID'] == t)]\n",
    "    for i in range(len(temp)-5):\n",
    "        X_final.append(temp[i:i+6])\n",
    "        traj_id.append(t)\n",
    "X_test = np.array(X_final)\n",
    "history = LossHistory()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/80\n",
      "9687/9687 [==============================] - 9s 898us/step - loss: 0.0386 - mean_squared_error: 0.0386\n",
      "Epoch 2/80\n",
      "9687/9687 [==============================] - 9s 909us/step - loss: 0.0076 - mean_squared_error: 0.0076\n",
      "Epoch 3/80\n",
      "9687/9687 [==============================] - 9s 922us/step - loss: 0.0057 - mean_squared_error: 0.0057\n",
      "Epoch 4/80\n",
      "9687/9687 [==============================] - 9s 912us/step - loss: 0.0043 - mean_squared_error: 0.0043\n",
      "Epoch 5/80\n",
      "9687/9687 [==============================] - 9s 904us/step - loss: 0.0032 - mean_squared_error: 0.0032\n",
      "Epoch 6/80\n",
      "9687/9687 [==============================] - 8s 870us/step - loss: 0.0024 - mean_squared_error: 0.0024\n",
      "Epoch 7/80\n",
      "9687/9687 [==============================] - 9s 883us/step - loss: 0.0019 - mean_squared_error: 0.0019\n",
      "Epoch 8/80\n",
      "9687/9687 [==============================] - 8s 862us/step - loss: 0.0016 - mean_squared_error: 0.0016\n",
      "Epoch 9/80\n",
      "9687/9687 [==============================] - 9s 904us/step - loss: 0.0014 - mean_squared_error: 0.0014\n",
      "Epoch 10/80\n",
      "9687/9687 [==============================] - 9s 915us/step - loss: 0.0012 - mean_squared_error: 0.0012\n",
      "Epoch 11/80\n",
      "9687/9687 [==============================] - 8s 877us/step - loss: 0.0011 - mean_squared_error: 0.0011\n",
      "Epoch 12/80\n",
      "9687/9687 [==============================] - 9s 923us/step - loss: 9.2516e-04 - mean_squared_error: 9.2516e-04\n",
      "Epoch 13/80\n",
      "9687/9687 [==============================] - 9s 894us/step - loss: 7.9539e-04 - mean_squared_error: 7.9539e-04\n",
      "Epoch 14/80\n",
      "9687/9687 [==============================] - 8s 856us/step - loss: 6.8214e-04 - mean_squared_error: 6.8214e-04\n",
      "Epoch 15/80\n",
      "9687/9687 [==============================] - 8s 864us/step - loss: 5.8018e-04 - mean_squared_error: 5.8018e-04\n",
      "Epoch 16/80\n",
      "9687/9687 [==============================] - 8s 856us/step - loss: 4.9429e-04 - mean_squared_error: 4.9429e-04\n",
      "Epoch 17/80\n",
      "9687/9687 [==============================] - 9s 912us/step - loss: 4.1600e-04 - mean_squared_error: 4.1600e-04\n",
      "Epoch 18/80\n",
      "9687/9687 [==============================] - 9s 912us/step - loss: 3.5298e-04 - mean_squared_error: 3.5298e-04\n",
      "Epoch 19/80\n",
      "9687/9687 [==============================] - 9s 918us/step - loss: 2.9489e-04 - mean_squared_error: 2.9489e-04\n",
      "Epoch 20/80\n",
      "9687/9687 [==============================] - 9s 887us/step - loss: 2.4673e-04 - mean_squared_error: 2.4673e-04\n",
      "Epoch 21/80\n",
      "9687/9687 [==============================] - 8s 865us/step - loss: 2.0544e-04 - mean_squared_error: 2.0544e-04\n",
      "Epoch 22/80\n",
      "9687/9687 [==============================] - 8s 864us/step - loss: 1.7331e-04 - mean_squared_error: 1.7331e-04\n",
      "Epoch 23/80\n",
      "9687/9687 [==============================] - 8s 865us/step - loss: 1.4201e-04 - mean_squared_error: 1.4201e-04\n",
      "Epoch 24/80\n",
      "9687/9687 [==============================] - 9s 917us/step - loss: 1.1691e-04 - mean_squared_error: 1.1691e-04\n",
      "Epoch 25/80\n",
      "9687/9687 [==============================] - 9s 909us/step - loss: 9.7539e-05 - mean_squared_error: 9.7539e-05\n",
      "Epoch 26/80\n",
      "9687/9687 [==============================] - 9s 916us/step - loss: 8.3370e-05 - mean_squared_error: 8.3370e-05\n",
      "Epoch 27/80\n",
      "9687/9687 [==============================] - 8s 869us/step - loss: 7.2635e-05 - mean_squared_error: 7.2635e-05\n",
      "Epoch 28/80\n",
      "9687/9687 [==============================] - 8s 854us/step - loss: 6.2228e-05 - mean_squared_error: 6.2228e-05\n",
      "Epoch 29/80\n",
      "9687/9687 [==============================] - 8s 866us/step - loss: 5.5195e-05 - mean_squared_error: 5.5195e-05\n",
      "Epoch 30/80\n",
      "9687/9687 [==============================] - 9s 909us/step - loss: 4.8939e-05 - mean_squared_error: 4.8939e-05\n",
      "Epoch 31/80\n",
      "9687/9687 [==============================] - 9s 911us/step - loss: 4.3998e-05 - mean_squared_error: 4.3998e-05\n",
      "Epoch 32/80\n",
      "9687/9687 [==============================] - 9s 909us/step - loss: 3.9242e-05 - mean_squared_error: 3.9242e-05\n",
      "Epoch 33/80\n",
      "9687/9687 [==============================] - 9s 925us/step - loss: 3.6060e-05 - mean_squared_error: 3.6060e-05\n",
      "Epoch 34/80\n",
      "9687/9687 [==============================] - 9s 881us/step - loss: 3.2088e-05 - mean_squared_error: 3.2088e-05\n",
      "Epoch 35/80\n",
      "9687/9687 [==============================] - 8s 869us/step - loss: 3.0780e-05 - mean_squared_error: 3.0780e-05\n",
      "Epoch 36/80\n",
      "9687/9687 [==============================] - 8s 875us/step - loss: 2.6728e-05 - mean_squared_error: 2.6728e-05\n",
      "Epoch 37/80\n",
      "9687/9687 [==============================] - 9s 919us/step - loss: 2.4766e-05 - mean_squared_error: 2.4766e-05\n",
      "Epoch 38/80\n",
      "9687/9687 [==============================] - 9s 911us/step - loss: 2.3695e-05 - mean_squared_error: 2.3695e-05\n",
      "Epoch 39/80\n",
      "9687/9687 [==============================] - 9s 922us/step - loss: 2.3030e-05 - mean_squared_error: 2.3030e-05\n",
      "Epoch 40/80\n",
      "9687/9687 [==============================] - 9s 917us/step - loss: 1.9574e-05 - mean_squared_error: 1.9574e-05\n",
      "Epoch 41/80\n",
      "9687/9687 [==============================] - 8s 866us/step - loss: 1.9436e-05 - mean_squared_error: 1.9436e-05\n",
      "Epoch 42/80\n",
      "9687/9687 [==============================] - 8s 845us/step - loss: 1.8071e-05 - mean_squared_error: 1.8071e-05\n",
      "Epoch 43/80\n",
      "9687/9687 [==============================] - 8s 876us/step - loss: 1.7919e-05 - mean_squared_error: 1.7919e-05\n",
      "Epoch 44/80\n",
      "9687/9687 [==============================] - 9s 914us/step - loss: 1.6377e-05 - mean_squared_error: 1.6377e-05\n",
      "Epoch 45/80\n",
      "9687/9687 [==============================] - 9s 910us/step - loss: 1.6542e-05 - mean_squared_error: 1.6542e-05\n",
      "Epoch 46/80\n",
      "9687/9687 [==============================] - 9s 915us/step - loss: 1.4698e-05 - mean_squared_error: 1.4698e-05\n",
      "Epoch 47/80\n",
      "9687/9687 [==============================] - 9s 908us/step - loss: 1.4460e-05 - mean_squared_error: 1.4460e-05\n",
      "Epoch 48/80\n",
      "9687/9687 [==============================] - 9s 881us/step - loss: 1.4912e-05 - mean_squared_error: 1.4912e-05\n",
      "Epoch 49/80\n",
      "9687/9687 [==============================] - 8s 836us/step - loss: 1.3937e-05 - mean_squared_error: 1.3937e-05\n",
      "Epoch 50/80\n",
      "9687/9687 [==============================] - 9s 891us/step - loss: 1.3105e-05 - mean_squared_error: 1.3105e-05\n",
      "Epoch 51/80\n",
      "9687/9687 [==============================] - 9s 917us/step - loss: 1.3629e-05 - mean_squared_error: 1.3629e-05\n",
      "Epoch 52/80\n",
      "9687/9687 [==============================] - 9s 923us/step - loss: 1.2075e-05 - mean_squared_error: 1.2075e-05\n",
      "Epoch 53/80\n",
      "9687/9687 [==============================] - 9s 907us/step - loss: 1.3067e-05 - mean_squared_error: 1.3067e-05\n",
      "Epoch 54/80\n",
      "9687/9687 [==============================] - 9s 910us/step - loss: 1.1498e-05 - mean_squared_error: 1.1498e-05\n",
      "Epoch 55/80\n",
      "9687/9687 [==============================] - 8s 855us/step - loss: 1.2090e-05 - mean_squared_error: 1.2090e-05\n",
      "Epoch 56/80\n",
      "9687/9687 [==============================] - 8s 836us/step - loss: 1.1940e-05 - mean_squared_error: 1.1940e-05\n",
      "Epoch 57/80\n",
      "9687/9687 [==============================] - 9s 893us/step - loss: 1.2761e-05 - mean_squared_error: 1.2761e-05\n",
      "Epoch 58/80\n",
      "9687/9687 [==============================] - 9s 913us/step - loss: 1.0794e-05 - mean_squared_error: 1.0794e-05\n",
      "Epoch 59/80\n",
      "9687/9687 [==============================] - 9s 905us/step - loss: 1.0427e-05 - mean_squared_error: 1.0427e-05\n",
      "Epoch 60/80\n",
      "9687/9687 [==============================] - 9s 912us/step - loss: 1.1847e-05 - mean_squared_error: 1.1847e-05\n",
      "Epoch 61/80\n",
      "9687/9687 [==============================] - 9s 920us/step - loss: 1.0751e-05 - mean_squared_error: 1.0751e-05\n",
      "Epoch 62/80\n",
      "9687/9687 [==============================] - 8s 873us/step - loss: 1.0052e-05 - mean_squared_error: 1.0052e-05\n",
      "Epoch 63/80\n",
      "9687/9687 [==============================] - 8s 848us/step - loss: 1.0989e-05 - mean_squared_error: 1.0989e-05\n",
      "Epoch 64/80\n",
      "9687/9687 [==============================] - 9s 909us/step - loss: 9.7486e-06 - mean_squared_error: 9.7486e-06\n",
      "Epoch 65/80\n",
      "9687/9687 [==============================] - 9s 909us/step - loss: 1.0077e-05 - mean_squared_error: 1.0077e-05\n",
      "Epoch 66/80\n",
      "9687/9687 [==============================] - 9s 914us/step - loss: 1.0490e-05 - mean_squared_error: 1.0490e-05\n",
      "Epoch 67/80\n",
      "9687/9687 [==============================] - 9s 915us/step - loss: 1.0159e-05 - mean_squared_error: 1.0159e-05\n",
      "Epoch 68/80\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9687/9687 [==============================] - 9s 902us/step - loss: 8.9881e-06 - mean_squared_error: 8.9881e-06\n",
      "Epoch 69/80\n",
      "9687/9687 [==============================] - 8s 858us/step - loss: 1.1410e-05 - mean_squared_error: 1.1410e-05\n",
      "Epoch 70/80\n",
      "9687/9687 [==============================] - 8s 833us/step - loss: 9.0982e-06 - mean_squared_error: 9.0982e-06\n",
      "Epoch 71/80\n",
      "9687/9687 [==============================] - 9s 903us/step - loss: 9.0551e-06 - mean_squared_error: 9.0551e-06\n",
      "Epoch 72/80\n",
      "9687/9687 [==============================] - 9s 907us/step - loss: 9.0482e-06 - mean_squared_error: 9.0482e-06\n",
      "Epoch 73/80\n",
      "9687/9687 [==============================] - 9s 911us/step - loss: 8.7634e-06 - mean_squared_error: 8.7634e-06\n",
      "Epoch 74/80\n",
      "9687/9687 [==============================] - 9s 914us/step - loss: 9.5940e-06 - mean_squared_error: 9.5940e-06\n",
      "Epoch 75/80\n",
      "9687/9687 [==============================] - 9s 887us/step - loss: 8.9792e-06 - mean_squared_error: 8.9792e-06\n",
      "Epoch 76/80\n",
      "9687/9687 [==============================] - 8s 846us/step - loss: 8.5018e-06 - mean_squared_error: 8.5018e-06\n",
      "Epoch 77/80\n",
      "9687/9687 [==============================] - 8s 857us/step - loss: 1.2257e-05 - mean_squared_error: 1.2257e-05\n",
      "Epoch 78/80\n",
      "9687/9687 [==============================] - 8s 853us/step - loss: 7.5521e-06 - mean_squared_error: 7.5521e-06\n",
      "Epoch 79/80\n",
      "9687/9687 [==============================] - 9s 914us/step - loss: 7.5762e-06 - mean_squared_error: 7.5762e-06\n",
      "Epoch 80/80\n",
      "9687/9687 [==============================] - 9s 917us/step - loss: 8.3686e-06 - mean_squared_error: 8.3686e-06\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_3_input (InputLayer)    (None, 6, 30)             0         \n",
      "_________________________________________________________________\n",
      "lstm_3 (LSTM)                (None, 6, 64)             24320     \n",
      "=================================================================\n",
      "Total params: 24,320\n",
      "Trainable params: 24,320\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "def build_model_ae():\n",
    "    m = Sequential()\n",
    "    m.add(LSTM(64, return_sequences=True, input_shape=(6,30)))\n",
    "    m.add(LSTM(32, return_sequences=True))\n",
    "    m.add(TimeDistributed(Dense(30)))\n",
    "    r = Adam(lr=0.001)\n",
    "    m.compile(optimizer=r, loss='mse', metrics=['mse'])\n",
    "    return m\n",
    "\n",
    "def build_model_lstm():\n",
    "    m = Sequential()\n",
    "    m.add(LSTM(32, return_sequences=True, input_shape=(6, 64)))\n",
    "    m.add(LSTM(64, return_sequences=True))\n",
    "    m.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    m.add(TimeDistributed(Dense(1024, activation='relu')))\n",
    "    m.add(TimeDistributed(Dense(891, activation='softmax')))\n",
    "    r = Adam(lr=0.001)\n",
    "    m.compile(optimizer=r, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "    return m\n",
    "\n",
    "model1 = build_model_ae()\n",
    "model1.fit(X, X, epochs=80, batch_size=32)\n",
    "# model1.fit(X_train, X_train, validation_data=(X_test, X_test), epochs=80, batch_size=32)\n",
    "model1 = Model(inputs=model1.inputs, outputs=model1.layers[0].output)\n",
    "model1.summary()\n",
    "X_train_vec = model1.predict(X)\n",
    "X_test_vec = model1.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "# X_train, X_test, y_train, y_test = train_test_split(X_train_vec, y, test_size=0.3, random_state=33)\n",
    "\n",
    "grid=pd.read_csv('grid1.csv')[['x','y']].values\n",
    "Y_train=[]\n",
    "for seq in y:\n",
    "    poses=[]\n",
    "    for mr in seq:\n",
    "        u1, u2, _, _ = utm.from_latlon(mr[0], mr[1])\n",
    "        test = np.array([u1, u2])\n",
    "        poses.append(np.argmin(np.sum(np.square(test - grid), axis=1)))\n",
    "    Y_train.append(poses)\n",
    "\n",
    "Y_train=to_categorical(np.array(Y_train),891)\n",
    "# Y_test=[]\n",
    "# y_test_utm=[]\n",
    "# for seq in y_test:\n",
    "#     poses=[]\n",
    "#     utms=[]\n",
    "#     for mr in seq:\n",
    "#         u1, u2, _, _ = utm.from_latlon(mr[0], mr[1])\n",
    "#         test = np.array([u1, u2])\n",
    "#         utms.append([u1, u2])\n",
    "#         poses.append(np.argmin(np.sum(np.square(test - grid), axis=1)))\n",
    "#     y_test_utm.append(utms)\n",
    "#     Y_test.append(poses)\n",
    "\n",
    "# Y_test=to_categorical(np.array(Y_test),891)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "9687/9687 [==============================] - 5s 530us/step - loss: 5.3043 - acc: 0.0457\n",
      "Epoch 2/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 4.6446 - acc: 0.0744\n",
      "Epoch 3/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 4.2033 - acc: 0.1056\n",
      "Epoch 4/100\n",
      "9687/9687 [==============================] - 4s 457us/step - loss: 3.8877 - acc: 0.1231\n",
      "Epoch 5/100\n",
      "9687/9687 [==============================] - 4s 441us/step - loss: 3.6996 - acc: 0.1376\n",
      "Epoch 6/100\n",
      "9687/9687 [==============================] - 4s 459us/step - loss: 3.5343 - acc: 0.1595\n",
      "Epoch 7/100\n",
      "9687/9687 [==============================] - 4s 447us/step - loss: 3.3489 - acc: 0.1779\n",
      "Epoch 8/100\n",
      "9687/9687 [==============================] - 4s 459us/step - loss: 3.1666 - acc: 0.1984\n",
      "Epoch 9/100\n",
      "9687/9687 [==============================] - 4s 450us/step - loss: 2.9569 - acc: 0.2314\n",
      "Epoch 10/100\n",
      "9687/9687 [==============================] - 4s 462us/step - loss: 2.7140 - acc: 0.2752\n",
      "Epoch 11/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 2.4302 - acc: 0.3280\n",
      "Epoch 12/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 2.1598 - acc: 0.3831\n",
      "Epoch 13/100\n",
      "9687/9687 [==============================] - 5s 483us/step - loss: 1.9045 - acc: 0.4400\n",
      "Epoch 14/100\n",
      "9687/9687 [==============================] - 5s 488us/step - loss: 1.6718 - acc: 0.4963\n",
      "Epoch 15/100\n",
      "9687/9687 [==============================] - 5s 480us/step - loss: 1.4678 - acc: 0.5500\n",
      "Epoch 16/100\n",
      "9687/9687 [==============================] - 5s 470us/step - loss: 1.3243 - acc: 0.5875\n",
      "Epoch 17/100\n",
      "9687/9687 [==============================] - 5s 483us/step - loss: 1.1657 - acc: 0.6329\n",
      "Epoch 18/100\n",
      "9687/9687 [==============================] - 4s 449us/step - loss: 1.0429 - acc: 0.6683\n",
      "Epoch 19/100\n",
      "9687/9687 [==============================] - 4s 452us/step - loss: 0.9341 - acc: 0.6981\n",
      "Epoch 20/100\n",
      "9687/9687 [==============================] - 4s 449us/step - loss: 0.8566 - acc: 0.7206\n",
      "Epoch 21/100\n",
      "9687/9687 [==============================] - 4s 431us/step - loss: 0.7660 - acc: 0.7475\n",
      "Epoch 22/100\n",
      "9687/9687 [==============================] - 5s 471us/step - loss: 0.7008 - acc: 0.7696\n",
      "Epoch 23/100\n",
      "9687/9687 [==============================] - 5s 482us/step - loss: 0.6409 - acc: 0.7884\n",
      "Epoch 24/100\n",
      "9687/9687 [==============================] - 5s 478us/step - loss: 0.5844 - acc: 0.8074\n",
      "Epoch 25/100\n",
      "9687/9687 [==============================] - 5s 472us/step - loss: 0.5542 - acc: 0.8170\n",
      "Epoch 26/100\n",
      "9687/9687 [==============================] - 5s 477us/step - loss: 0.5137 - acc: 0.8286\n",
      "Epoch 27/100\n",
      "9687/9687 [==============================] - 5s 480us/step - loss: 0.4826 - acc: 0.8383\n",
      "Epoch 28/100\n",
      "9687/9687 [==============================] - 5s 476us/step - loss: 0.4727 - acc: 0.8407\n",
      "Epoch 29/100\n",
      "9687/9687 [==============================] - 5s 477us/step - loss: 0.4265 - acc: 0.8571\n",
      "Epoch 30/100\n",
      "9687/9687 [==============================] - 5s 469us/step - loss: 0.4136 - acc: 0.8612\n",
      "Epoch 31/100\n",
      "9687/9687 [==============================] - 5s 474us/step - loss: 0.3743 - acc: 0.8748\n",
      "Epoch 32/100\n",
      "9687/9687 [==============================] - 4s 439us/step - loss: 0.3502 - acc: 0.8832\n",
      "Epoch 33/100\n",
      "9687/9687 [==============================] - 4s 447us/step - loss: 0.3585 - acc: 0.8800\n",
      "Epoch 34/100\n",
      "9687/9687 [==============================] - 4s 433us/step - loss: 0.3580 - acc: 0.8782\n",
      "Epoch 35/100\n",
      "9687/9687 [==============================] - 4s 463us/step - loss: 0.3269 - acc: 0.8891\n",
      "Epoch 36/100\n",
      "9687/9687 [==============================] - 5s 469us/step - loss: 0.3117 - acc: 0.8958\n",
      "Epoch 37/100\n",
      "9687/9687 [==============================] - 5s 471us/step - loss: 0.2926 - acc: 0.9004\n",
      "Epoch 38/100\n",
      "9687/9687 [==============================] - 5s 477us/step - loss: 0.2798 - acc: 0.9038\n",
      "Epoch 39/100\n",
      "9687/9687 [==============================] - 5s 477us/step - loss: 0.2563 - acc: 0.9142\n",
      "Epoch 40/100\n",
      "9687/9687 [==============================] - 5s 468us/step - loss: 0.2771 - acc: 0.9068\n",
      "Epoch 41/100\n",
      "9687/9687 [==============================] - 5s 473us/step - loss: 0.2685 - acc: 0.9080\n",
      "Epoch 42/100\n",
      "9687/9687 [==============================] - 5s 478us/step - loss: 0.2451 - acc: 0.9174\n",
      "Epoch 43/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 0.2701 - acc: 0.9057\n",
      "Epoch 44/100\n",
      "9687/9687 [==============================] - 5s 473us/step - loss: 0.2272 - acc: 0.9220\n",
      "Epoch 45/100\n",
      "9687/9687 [==============================] - 4s 436us/step - loss: 0.2158 - acc: 0.9264\n",
      "Epoch 46/100\n",
      "9687/9687 [==============================] - 4s 460us/step - loss: 0.2003 - acc: 0.9319\n",
      "Epoch 47/100\n",
      "9687/9687 [==============================] - 4s 440us/step - loss: 0.2236 - acc: 0.9237\n",
      "Epoch 48/100\n",
      "9687/9687 [==============================] - 4s 450us/step - loss: 0.2025 - acc: 0.9308\n",
      "Epoch 49/100\n",
      "9687/9687 [==============================] - 5s 485us/step - loss: 0.2285 - acc: 0.9219\n",
      "Epoch 50/100\n",
      "9687/9687 [==============================] - 5s 482us/step - loss: 0.1933 - acc: 0.9338\n",
      "Epoch 51/100\n",
      "9687/9687 [==============================] - 5s 477us/step - loss: 0.1856 - acc: 0.9366\n",
      "Epoch 52/100\n",
      "9687/9687 [==============================] - 5s 472us/step - loss: 0.1931 - acc: 0.9337\n",
      "Epoch 53/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 0.1831 - acc: 0.9375\n",
      "Epoch 54/100\n",
      "9687/9687 [==============================] - 5s 482us/step - loss: 0.2087 - acc: 0.9304\n",
      "Epoch 55/100\n",
      "9687/9687 [==============================] - 5s 492us/step - loss: 0.1690 - acc: 0.9418\n",
      "Epoch 56/100\n",
      "9687/9687 [==============================] - 5s 472us/step - loss: 0.1750 - acc: 0.9399\n",
      "Epoch 57/100\n",
      "9687/9687 [==============================] - 5s 466us/step - loss: 0.1571 - acc: 0.9459\n",
      "Epoch 58/100\n",
      "9687/9687 [==============================] - 4s 448us/step - loss: 0.1610 - acc: 0.9443\n",
      "Epoch 59/100\n",
      "9687/9687 [==============================] - 4s 433us/step - loss: 0.1659 - acc: 0.9439\n",
      "Epoch 60/100\n",
      "9687/9687 [==============================] - 4s 454us/step - loss: 0.1628 - acc: 0.9440\n",
      "Epoch 61/100\n",
      "9687/9687 [==============================] - 4s 429us/step - loss: 0.1750 - acc: 0.9403\n",
      "Epoch 62/100\n",
      "9687/9687 [==============================] - 4s 462us/step - loss: 0.1399 - acc: 0.9520\n",
      "Epoch 63/100\n",
      "9687/9687 [==============================] - 4s 420us/step - loss: 0.1485 - acc: 0.9485\n",
      "Epoch 64/100\n",
      "9687/9687 [==============================] - 4s 443us/step - loss: 0.1581 - acc: 0.9459\n",
      "Epoch 65/100\n",
      "9687/9687 [==============================] - 5s 472us/step - loss: 0.1343 - acc: 0.9538\n",
      "Epoch 66/100\n",
      "9687/9687 [==============================] - 4s 436us/step - loss: 0.1507 - acc: 0.9489\n",
      "Epoch 67/100\n",
      "9687/9687 [==============================] - 5s 478us/step - loss: 0.1497 - acc: 0.9478\n",
      "Epoch 68/100\n",
      "9687/9687 [==============================] - 5s 476us/step - loss: 0.1326 - acc: 0.9561\n",
      "Epoch 69/100\n",
      "9687/9687 [==============================] - 5s 474us/step - loss: 0.1427 - acc: 0.9512\n",
      "Epoch 70/100\n",
      "9687/9687 [==============================] - 5s 481us/step - loss: 0.1268 - acc: 0.9554\n",
      "Epoch 71/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 0.1237 - acc: 0.9576\n",
      "Epoch 72/100\n",
      "9687/9687 [==============================] - 4s 440us/step - loss: 0.1367 - acc: 0.9542\n",
      "Epoch 73/100\n",
      "9687/9687 [==============================] - 5s 470us/step - loss: 0.1283 - acc: 0.9562\n",
      "Epoch 74/100\n",
      "9687/9687 [==============================] - 4s 432us/step - loss: 0.1251 - acc: 0.9582\n",
      "Epoch 75/100\n",
      "9687/9687 [==============================] - 5s 473us/step - loss: 0.1458 - acc: 0.9506\n",
      "Epoch 76/100\n",
      "9687/9687 [==============================] - 5s 466us/step - loss: 0.1211 - acc: 0.9580\n",
      "Epoch 77/100\n",
      "9687/9687 [==============================] - 4s 435us/step - loss: 0.1176 - acc: 0.9590\n",
      "Epoch 78/100\n",
      "9687/9687 [==============================] - 5s 474us/step - loss: 0.1096 - acc: 0.9627\n",
      "Epoch 79/100\n",
      "9687/9687 [==============================] - 5s 487us/step - loss: 0.1203 - acc: 0.9586\n",
      "Epoch 80/100\n",
      "9687/9687 [==============================] - 5s 467us/step - loss: 0.1236 - acc: 0.9586\n",
      "Epoch 81/100\n",
      "9687/9687 [==============================] - 5s 482us/step - loss: 0.1032 - acc: 0.9644\n",
      "Epoch 82/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "9687/9687 [==============================] - 5s 477us/step - loss: 0.1164 - acc: 0.9593\n",
      "Epoch 83/100\n",
      "9687/9687 [==============================] - 5s 472us/step - loss: 0.1263 - acc: 0.9566\n",
      "Epoch 84/100\n",
      "9687/9687 [==============================] - 5s 480us/step - loss: 0.1128 - acc: 0.9612\n",
      "Epoch 85/100\n",
      "9687/9687 [==============================] - 4s 457us/step - loss: 0.1207 - acc: 0.9584\n",
      "Epoch 86/100\n",
      "9687/9687 [==============================] - 4s 446us/step - loss: 0.1006 - acc: 0.9649\n",
      "Epoch 87/100\n",
      "9687/9687 [==============================] - 5s 470us/step - loss: 0.1037 - acc: 0.9649\n",
      "Epoch 88/100\n",
      "9687/9687 [==============================] - 4s 428us/step - loss: 0.0998 - acc: 0.9652\n",
      "Epoch 89/100\n",
      "9687/9687 [==============================] - 4s 443us/step - loss: 0.1062 - acc: 0.9636\n",
      "Epoch 90/100\n",
      "9687/9687 [==============================] - 5s 465us/step - loss: 0.1095 - acc: 0.9626\n",
      "Epoch 91/100\n",
      "9687/9687 [==============================] - 5s 474us/step - loss: 0.0907 - acc: 0.9688\n",
      "Epoch 92/100\n",
      "9687/9687 [==============================] - 5s 474us/step - loss: 0.1063 - acc: 0.9635\n",
      "Epoch 93/100\n",
      "9687/9687 [==============================] - 5s 467us/step - loss: 0.0965 - acc: 0.9667\n",
      "Epoch 94/100\n",
      "9687/9687 [==============================] - 5s 471us/step - loss: 0.0878 - acc: 0.9691\n",
      "Epoch 95/100\n",
      "9687/9687 [==============================] - 5s 476us/step - loss: 0.1086 - acc: 0.9634\n",
      "Epoch 96/100\n",
      "9687/9687 [==============================] - 4s 464us/step - loss: 0.0938 - acc: 0.9677\n",
      "Epoch 97/100\n",
      "9687/9687 [==============================] - 5s 475us/step - loss: 0.0947 - acc: 0.9665\n",
      "Epoch 98/100\n",
      "9687/9687 [==============================] - 5s 466us/step - loss: 0.0955 - acc: 0.9671\n",
      "Epoch 99/100\n",
      "9687/9687 [==============================] - 4s 449us/step - loss: 0.0917 - acc: 0.9676\n",
      "Epoch 100/100\n",
      "9687/9687 [==============================] - 4s 454us/step - loss: 0.1101 - acc: 0.9636\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_5 (LSTM)                (None, 6, 32)             12416     \n",
      "_________________________________________________________________\n",
      "lstm_6 (LSTM)                (None, 6, 64)             24832     \n",
      "_________________________________________________________________\n",
      "time_distributed_3 (TimeDist (None, 6, 1024)           66560     \n",
      "_________________________________________________________________\n",
      "time_distributed_4 (TimeDist (None, 6, 1024)           1049600   \n",
      "_________________________________________________________________\n",
      "time_distributed_5 (TimeDist (None, 6, 891)            913275    \n",
      "=================================================================\n",
      "Total params: 2,066,683\n",
      "Trainable params: 2,066,683\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model2 = build_model_lstm()\n",
    "model2.fit(X_train_vec, Y_train,epochs=100, batch_size=64)\n",
    "model2.summary()\n",
    "y_result = [0]*len(data_test)\n",
    "y_result_count = [0]*len(data_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def Dist_Error(pred,real):\n",
    "    errors=np.abs(pred-real)\n",
    "    result=[math.sqrt(math.pow(i[0],2)+math.pow(i[1],2))for i in errors]\n",
    "    return np.array(result)\n",
    "testRe=model2.predict_classes(X_test)\n",
    "zone_number = 51\n",
    "zone_letter = 'R'\n",
    "testRe=testRe.reshape(-1)\n",
    "y_test_utm=np.array(y_test_utm).reshape(-1,2)\n",
    "\n",
    "testFi=[[grid[i][0], grid[i][1]] for i in testRe]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "errors=Dist_Error(np.array(testFi),np.array(y_test_utm))\n",
    "errors=np.array(errors)\n",
    "print(np.median(errors))\n",
    "print(np.mean(errors))\n",
    "print(np.sort(errors)[int(len(errors)*0.9)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.arange(0,np.max(errors))\n",
    "error_y = [len(errors[errors < i])/len(errors) for i in x]\n",
    "plt.plot(x, error_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = model2.predict_classes(X_test_vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "def traj_merge(traj_id,trajs,code=0):\n",
    "    maxleng=len(trajs[0])\n",
    "    last=-1\n",
    "    result=[]\n",
    "    for i in range(len(traj_id)):\n",
    "        if traj_id[i]!=last:\n",
    "            result+=trajs[i]\n",
    "            last=traj_id[i]\n",
    "        else:\n",
    "            result.append(trajs[i][maxleng-1])\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_p = traj_merge(traj_id,y_pred.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "success\n"
     ]
    }
   ],
   "source": [
    "grid = pd.read_csv('grid1.csv').values\n",
    "zone_number = 51\n",
    "zone_letter = 'R'\n",
    "y_final = [[utm.to_latlon(grid[i][1], grid[i][2], zone_letter=zone_letter, zone_number=zone_number)[1],\n",
    "           utm.to_latlon(grid[i][1], grid[i][2], zone_letter=zone_letter, zone_number=zone_number)[0]] for i in y_p]\n",
    "y_final = np.array(y_final)\n",
    "df_pred = pd.DataFrame(data={'Longitude':y_final[:,0], 'Latitude':y_final[:,1]})\n",
    "df_pred.to_csv('pred6.csv', index=False)\n",
    "print('success')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
