{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 7535 samples, validate on 2512 samples\n",
      "Epoch 1/500\n",
      "7535/7535 [==============================] - 4s 556us/step - loss: 0.3048 - mean_squared_error: 0.0489 - val_loss: 0.2660 - val_mean_squared_error: 0.0356\n",
      "Epoch 2/500\n",
      "7535/7535 [==============================] - 3s 356us/step - loss: 0.2303 - mean_squared_error: 0.0268 - val_loss: 0.2011 - val_mean_squared_error: 0.0203\n",
      "Epoch 3/500\n",
      "7535/7535 [==============================] - 2s 315us/step - loss: 0.1946 - mean_squared_error: 0.0191 - val_loss: 0.1716 - val_mean_squared_error: 0.0148\n",
      "Epoch 4/500\n",
      "7535/7535 [==============================] - 3s 354us/step - loss: 0.1736 - mean_squared_error: 0.0152 - val_loss: 0.1766 - val_mean_squared_error: 0.0156\n",
      "Epoch 5/500\n",
      "7535/7535 [==============================] - 2s 276us/step - loss: 0.1701 - mean_squared_error: 0.0146 - val_loss: 0.1527 - val_mean_squared_error: 0.0117\n",
      "Epoch 6/500\n",
      "7535/7535 [==============================] - 2s 251us/step - loss: 0.1582 - mean_squared_error: 0.0126 - val_loss: 0.1483 - val_mean_squared_error: 0.0111\n",
      "Epoch 7/500\n",
      "7535/7535 [==============================] - 2s 242us/step - loss: 0.1548 - mean_squared_error: 0.0121 - val_loss: 0.1412 - val_mean_squared_error: 0.0100\n",
      "Epoch 8/500\n",
      "7535/7535 [==============================] - 2s 249us/step - loss: 0.1467 - mean_squared_error: 0.0108 - val_loss: 0.1337 - val_mean_squared_error: 0.0090\n",
      "Epoch 9/500\n",
      "7535/7535 [==============================] - 2s 248us/step - loss: 0.1424 - mean_squared_error: 0.0102 - val_loss: 0.1436 - val_mean_squared_error: 0.0104\n",
      "Epoch 10/500\n",
      "7535/7535 [==============================] - 3s 347us/step - loss: 0.1410 - mean_squared_error: 0.0100 - val_loss: 0.1367 - val_mean_squared_error: 0.0094\n",
      "Epoch 11/500\n",
      "7535/7535 [==============================] - 3s 345us/step - loss: 0.1321 - mean_squared_error: 0.0088 - val_loss: 0.1239 - val_mean_squared_error: 0.0077\n",
      "Epoch 12/500\n",
      "7535/7535 [==============================] - 2s 283us/step - loss: 0.1291 - mean_squared_error: 0.0084 - val_loss: 0.1231 - val_mean_squared_error: 0.0076\n",
      "Epoch 13/500\n",
      "7535/7535 [==============================] - 3s 344us/step - loss: 0.1269 - mean_squared_error: 0.0081 - val_loss: 0.1161 - val_mean_squared_error: 0.0068\n",
      "Epoch 14/500\n",
      "7535/7535 [==============================] - 2s 323us/step - loss: 0.1224 - mean_squared_error: 0.0076 - val_loss: 0.1145 - val_mean_squared_error: 0.0066\n",
      "Epoch 15/500\n",
      "7535/7535 [==============================] - 2s 263us/step - loss: 0.1172 - mean_squared_error: 0.0070 - val_loss: 0.1106 - val_mean_squared_error: 0.0062\n",
      "Epoch 16/500\n",
      "7535/7535 [==============================] - 2s 247us/step - loss: 0.1106 - mean_squared_error: 0.0062 - val_loss: 0.1098 - val_mean_squared_error: 0.0061\n",
      "Epoch 17/500\n",
      "7535/7535 [==============================] - 3s 348us/step - loss: 0.1101 - mean_squared_error: 0.0061 - val_loss: 0.1041 - val_mean_squared_error: 0.0055\n",
      "Epoch 18/500\n",
      "7535/7535 [==============================] - 2s 324us/step - loss: 0.1041 - mean_squared_error: 0.0055 - val_loss: 0.1185 - val_mean_squared_error: 0.0071\n",
      "Epoch 19/500\n",
      "7535/7535 [==============================] - 2s 273us/step - loss: 0.1040 - mean_squared_error: 0.0055 - val_loss: 0.1045 - val_mean_squared_error: 0.0055\n",
      "Epoch 20/500\n",
      "7535/7535 [==============================] - 2s 268us/step - loss: 0.1007 - mean_squared_error: 0.0051 - val_loss: 0.1016 - val_mean_squared_error: 0.0052\n",
      "Epoch 21/500\n",
      "7535/7535 [==============================] - 2s 308us/step - loss: 0.0997 - mean_squared_error: 0.0051 - val_loss: 0.0959 - val_mean_squared_error: 0.0047\n",
      "Epoch 22/500\n",
      "7535/7535 [==============================] - 3s 393us/step - loss: 0.0964 - mean_squared_error: 0.0047 - val_loss: 0.1211 - val_mean_squared_error: 0.0074\n",
      "Epoch 23/500\n",
      "7535/7535 [==============================] - 2s 329us/step - loss: 0.0919 - mean_squared_error: 0.0043 - val_loss: 0.0928 - val_mean_squared_error: 0.0044\n",
      "Epoch 24/500\n",
      "7535/7535 [==============================] - 2s 268us/step - loss: 0.0879 - mean_squared_error: 0.0039 - val_loss: 0.0879 - val_mean_squared_error: 0.0039\n",
      "Epoch 25/500\n",
      "7535/7535 [==============================] - 2s 241us/step - loss: 0.0859 - mean_squared_error: 0.0037 - val_loss: 0.1004 - val_mean_squared_error: 0.0051\n",
      "Epoch 26/500\n",
      "7535/7535 [==============================] - 2s 247us/step - loss: 0.0849 - mean_squared_error: 0.0037 - val_loss: 0.0908 - val_mean_squared_error: 0.0042\n",
      "Epoch 27/500\n",
      "7535/7535 [==============================] - 2s 245us/step - loss: 0.0865 - mean_squared_error: 0.0038 - val_loss: 0.0879 - val_mean_squared_error: 0.0039\n",
      "Epoch 28/500\n",
      "7535/7535 [==============================] - 2s 238us/step - loss: 0.0828 - mean_squared_error: 0.0035 - val_loss: 0.0837 - val_mean_squared_error: 0.0036\n",
      "Epoch 29/500\n",
      "7535/7535 [==============================] - 2s 236us/step - loss: 0.0811 - mean_squared_error: 0.0034 - val_loss: 0.0920 - val_mean_squared_error: 0.0043\n",
      "Epoch 30/500\n",
      "7535/7535 [==============================] - 2s 246us/step - loss: 0.0795 - mean_squared_error: 0.0032 - val_loss: 0.0765 - val_mean_squared_error: 0.0030\n",
      "Epoch 31/500\n",
      "7535/7535 [==============================] - 2s 246us/step - loss: 0.0781 - mean_squared_error: 0.0031 - val_loss: 0.0758 - val_mean_squared_error: 0.0029\n",
      "Epoch 32/500\n",
      "7535/7535 [==============================] - 2s 247us/step - loss: 0.0743 - mean_squared_error: 0.0028 - val_loss: 0.0816 - val_mean_squared_error: 0.0034\n",
      "Epoch 33/500\n",
      "7535/7535 [==============================] - 2s 248us/step - loss: 0.0739 - mean_squared_error: 0.0028 - val_loss: 0.0749 - val_mean_squared_error: 0.0029\n",
      "Epoch 34/500\n",
      "7535/7535 [==============================] - 2s 240us/step - loss: 0.0751 - mean_squared_error: 0.0029 - val_loss: 0.0730 - val_mean_squared_error: 0.0027\n",
      "Epoch 35/500\n",
      "7535/7535 [==============================] - 2s 239us/step - loss: 0.0695 - mean_squared_error: 0.0024 - val_loss: 0.0742 - val_mean_squared_error: 0.0028\n",
      "Epoch 36/500\n",
      "7535/7535 [==============================] - 2s 252us/step - loss: 0.0713 - mean_squared_error: 0.0026 - val_loss: 0.0758 - val_mean_squared_error: 0.0030\n",
      "Epoch 37/500\n",
      "7535/7535 [==============================] - 2s 245us/step - loss: 0.0705 - mean_squared_error: 0.0025 - val_loss: 0.0730 - val_mean_squared_error: 0.0027\n",
      "Epoch 38/500\n",
      "7535/7535 [==============================] - 2s 237us/step - loss: 0.0675 - mean_squared_error: 0.0023 - val_loss: 0.0716 - val_mean_squared_error: 0.0026\n",
      "Epoch 39/500\n",
      "7535/7535 [==============================] - 3s 379us/step - loss: 0.0653 - mean_squared_error: 0.0022 - val_loss: 0.0736 - val_mean_squared_error: 0.0028\n",
      "Epoch 40/500\n",
      "7535/7535 [==============================] - 4s 584us/step - loss: 0.0670 - mean_squared_error: 0.0023 - val_loss: 0.0760 - val_mean_squared_error: 0.0030\n",
      "Epoch 41/500\n",
      "7535/7535 [==============================] - 3s 333us/step - loss: 0.0639 - mean_squared_error: 0.0021 - val_loss: 0.0718 - val_mean_squared_error: 0.0026\n",
      "Epoch 42/500\n",
      "7535/7535 [==============================] - 2s 264us/step - loss: 0.0624 - mean_squared_error: 0.0020 - val_loss: 0.0706 - val_mean_squared_error: 0.0026\n",
      "Epoch 43/500\n",
      "7535/7535 [==============================] - 2s 257us/step - loss: 0.0617 - mean_squared_error: 0.0019 - val_loss: 0.0778 - val_mean_squared_error: 0.0031\n",
      "Epoch 44/500\n",
      "7535/7535 [==============================] - 2s 265us/step - loss: 0.0614 - mean_squared_error: 0.0019 - val_loss: 0.0672 - val_mean_squared_error: 0.0024\n",
      "Epoch 45/500\n",
      "7535/7535 [==============================] - 2s 288us/step - loss: 0.0612 - mean_squared_error: 0.0019 - val_loss: 0.0718 - val_mean_squared_error: 0.0027\n",
      "Epoch 46/500\n",
      "7535/7535 [==============================] - 2s 265us/step - loss: 0.0585 - mean_squared_error: 0.0017 - val_loss: 0.0687 - val_mean_squared_error: 0.0024\n",
      "Epoch 47/500\n",
      "7535/7535 [==============================] - 2s 261us/step - loss: 0.0581 - mean_squared_error: 0.0017 - val_loss: 0.0685 - val_mean_squared_error: 0.0024\n",
      "Epoch 48/500\n",
      "7535/7535 [==============================] - 2s 289us/step - loss: 0.0620 - mean_squared_error: 0.0020 - val_loss: 0.0683 - val_mean_squared_error: 0.0024\n",
      "Epoch 49/500\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "7535/7535 [==============================] - 2s 217us/step - loss: 0.0559 - mean_squared_error: 0.0016 - val_loss: 0.0777 - val_mean_squared_error: 0.0031\n",
      "Epoch 50/500\n",
      "7535/7535 [==============================] - 2s 202us/step - loss: 0.0558 - mean_squared_error: 0.0016 - val_loss: 0.0635 - val_mean_squared_error: 0.0021\n",
      "Epoch 51/500\n",
      "7535/7535 [==============================] - 1s 197us/step - loss: 0.0547 - mean_squared_error: 0.0015 - val_loss: 0.0690 - val_mean_squared_error: 0.0025\n",
      "Epoch 52/500\n",
      "7535/7535 [==============================] - 2s 208us/step - loss: 0.0553 - mean_squared_error: 0.0016 - val_loss: 0.0662 - val_mean_squared_error: 0.0023\n",
      "Epoch 53/500\n",
      "7535/7535 [==============================] - 2s 214us/step - loss: 0.0546 - mean_squared_error: 0.0015 - val_loss: 0.0725 - val_mean_squared_error: 0.0027\n",
      "Epoch 54/500\n",
      "7535/7535 [==============================] - 1s 195us/step - loss: 0.0566 - mean_squared_error: 0.0016 - val_loss: 0.0622 - val_mean_squared_error: 0.0020\n",
      "Epoch 55/500\n",
      "7535/7535 [==============================] - 2s 254us/step - loss: 0.0534 - mean_squared_error: 0.0014 - val_loss: 0.0703 - val_mean_squared_error: 0.0025\n",
      "Epoch 56/500\n",
      "7535/7535 [==============================] - 2s 286us/step - loss: 0.0516 - mean_squared_error: 0.0014 - val_loss: 0.0604 - val_mean_squared_error: 0.0019\n",
      "Epoch 57/500\n",
      "7535/7535 [==============================] - 2s 288us/step - loss: 0.0524 - mean_squared_error: 0.0014 - val_loss: 0.0672 - val_mean_squared_error: 0.0023\n",
      "Epoch 58/500\n",
      "7535/7535 [==============================] - 2s 277us/step - loss: 0.0517 - mean_squared_error: 0.0014 - val_loss: 0.0645 - val_mean_squared_error: 0.0022\n",
      "Epoch 59/500\n",
      "7535/7535 [==============================] - 3s 359us/step - loss: 0.0505 - mean_squared_error: 0.0013 - val_loss: 0.0658 - val_mean_squared_error: 0.0022\n",
      "Epoch 60/500\n",
      "7535/7535 [==============================] - 3s 386us/step - loss: 0.0506 - mean_squared_error: 0.0013 - val_loss: 0.0618 - val_mean_squared_error: 0.0020\n",
      "Epoch 61/500\n",
      "7535/7535 [==============================] - 2s 299us/step - loss: 0.0476 - mean_squared_error: 0.0012 - val_loss: 0.0612 - val_mean_squared_error: 0.0020\n",
      "Epoch 62/500\n",
      "7535/7535 [==============================] - 2s 253us/step - loss: 0.0507 - mean_squared_error: 0.0013 - val_loss: 0.0594 - val_mean_squared_error: 0.0018\n",
      "Epoch 63/500\n",
      "7535/7535 [==============================] - 2s 242us/step - loss: 0.0484 - mean_squared_error: 0.0012 - val_loss: 0.0595 - val_mean_squared_error: 0.0019\n",
      "Epoch 64/500\n",
      "7535/7535 [==============================] - 2s 242us/step - loss: 0.0478 - mean_squared_error: 0.0012 - val_loss: 0.0582 - val_mean_squared_error: 0.0018\n",
      "Epoch 65/500\n",
      "7535/7535 [==============================] - 2s 244us/step - loss: 0.0468 - mean_squared_error: 0.0011 - val_loss: 0.0621 - val_mean_squared_error: 0.0020\n",
      "Epoch 66/500\n",
      "7535/7535 [==============================] - 2s 241us/step - loss: 0.0462 - mean_squared_error: 0.0011 - val_loss: 0.0602 - val_mean_squared_error: 0.0019\n",
      "Epoch 67/500\n",
      "7535/7535 [==============================] - 2s 241us/step - loss: 0.0489 - mean_squared_error: 0.0012 - val_loss: 0.0712 - val_mean_squared_error: 0.0026\n",
      "Epoch 68/500\n",
      "7535/7535 [==============================] - 2s 240us/step - loss: 0.0469 - mean_squared_error: 0.0011 - val_loss: 0.0602 - val_mean_squared_error: 0.0019\n",
      "Epoch 69/500\n",
      "7535/7535 [==============================] - 2s 261us/step - loss: 0.0448 - mean_squared_error: 0.0010 - val_loss: 0.0549 - val_mean_squared_error: 0.0016\n",
      "Epoch 70/500\n",
      "7535/7535 [==============================] - 2s 208us/step - loss: 0.0457 - mean_squared_error: 0.0011 - val_loss: 0.0573 - val_mean_squared_error: 0.0017\n",
      "Epoch 71/500\n",
      "7535/7535 [==============================] - 1s 193us/step - loss: 0.0446 - mean_squared_error: 0.0010 - val_loss: 0.0568 - val_mean_squared_error: 0.0017\n",
      "Epoch 72/500\n",
      "7535/7535 [==============================] - 1s 193us/step - loss: 0.0471 - mean_squared_error: 0.0011 - val_loss: 0.0688 - val_mean_squared_error: 0.0025\n",
      "Epoch 73/500\n",
      "7535/7535 [==============================] - 2s 286us/step - loss: 0.0436 - mean_squared_error: 9.6894e-04 - val_loss: 0.0557 - val_mean_squared_error: 0.0016\n",
      "Epoch 74/500\n",
      "7535/7535 [==============================] - 2s 285us/step - loss: 0.0423 - mean_squared_error: 9.0980e-04 - val_loss: 0.0569 - val_mean_squared_error: 0.0017\n",
      "Epoch 75/500\n",
      "7535/7535 [==============================] - 1s 191us/step - loss: 0.0437 - mean_squared_error: 9.7079e-04 - val_loss: 0.0613 - val_mean_squared_error: 0.0020\n",
      "Epoch 76/500\n",
      "7535/7535 [==============================] - 2s 231us/step - loss: 0.0439 - mean_squared_error: 9.8129e-04 - val_loss: 0.0585 - val_mean_squared_error: 0.0018\n",
      "Epoch 77/500\n",
      "7535/7535 [==============================] - 1s 188us/step - loss: 0.0417 - mean_squared_error: 8.8831e-04 - val_loss: 0.0568 - val_mean_squared_error: 0.0017\n",
      "Epoch 78/500\n",
      "7535/7535 [==============================] - 1s 192us/step - loss: 0.0417 - mean_squared_error: 8.8429e-04 - val_loss: 0.0617 - val_mean_squared_error: 0.0020\n",
      "Epoch 79/500\n",
      "7535/7535 [==============================] - 2s 238us/step - loss: 0.0425 - mean_squared_error: 9.2511e-04 - val_loss: 0.0549 - val_mean_squared_error: 0.0016\n",
      "Epoch 80/500\n",
      "7535/7535 [==============================] - 2s 276us/step - loss: 0.0408 - mean_squared_error: 8.4726e-04 - val_loss: 0.0688 - val_mean_squared_error: 0.0024\n",
      "Epoch 81/500\n",
      "7535/7535 [==============================] - 2s 264us/step - loss: 0.0405 - mean_squared_error: 8.3208e-04 - val_loss: 0.0553 - val_mean_squared_error: 0.0016\n",
      "Epoch 82/500\n",
      "7535/7535 [==============================] - 2s 229us/step - loss: 0.0411 - mean_squared_error: 8.6338e-04 - val_loss: 0.0532 - val_mean_squared_error: 0.0015\n",
      "Epoch 83/500\n",
      "7535/7535 [==============================] - 2s 266us/step - loss: 0.0395 - mean_squared_error: 8.0013e-04 - val_loss: 0.0584 - val_mean_squared_error: 0.0018\n",
      "Epoch 84/500\n",
      "7535/7535 [==============================] - 2s 241us/step - loss: 0.0408 - mean_squared_error: 8.4896e-04 - val_loss: 0.0583 - val_mean_squared_error: 0.0018\n",
      "Epoch 85/500\n",
      "7535/7535 [==============================] - 2s 257us/step - loss: 0.0391 - mean_squared_error: 7.7932e-04 - val_loss: 0.0552 - val_mean_squared_error: 0.0016\n",
      "Epoch 86/500\n",
      "7535/7535 [==============================] - 2s 276us/step - loss: 0.0380 - mean_squared_error: 7.3450e-04 - val_loss: 0.0559 - val_mean_squared_error: 0.0017\n",
      "Epoch 87/500\n",
      "7535/7535 [==============================] - 2s 200us/step - loss: 0.0417 - mean_squared_error: 8.8863e-04 - val_loss: 0.0544 - val_mean_squared_error: 0.0015\n",
      "Epoch 88/500\n",
      "7535/7535 [==============================] - 1s 185us/step - loss: 0.0395 - mean_squared_error: 7.9371e-04 - val_loss: 0.0561 - val_mean_squared_error: 0.0016\n",
      "Epoch 89/500\n",
      "7535/7535 [==============================] - 2s 241us/step - loss: 0.0411 - mean_squared_error: 8.6017e-04 - val_loss: 0.0568 - val_mean_squared_error: 0.0017\n",
      "Epoch 90/500\n",
      "7535/7535 [==============================] - 3s 334us/step - loss: 0.0381 - mean_squared_error: 7.3780e-04 - val_loss: 0.0555 - val_mean_squared_error: 0.0016\n",
      "Epoch 91/500\n",
      "3008/7535 [==========>...................] - ETA: 1s - loss: 0.0445 - mean_squared_error: 0.0010    "
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-6dad17f2d33e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     98\u001b[0m \u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_test_split\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     99\u001b[0m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mbuild_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 100\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m500\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m64\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcallbacks\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mhistory\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    101\u001b[0m \u001b[0mhistory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'epoch'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m \u001b[0;31m# data_test = pd.read_csv('new_formatted_.csv')\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.7/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.7/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.7/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/keras/lib/python3.7/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from keras.models import Sequential, Model\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Flatten, Dropout, BatchNormalization\n",
    "from keras import optimizers\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import keras\n",
    "import matplotlib.pyplot as plt\n",
    "import utm\n",
    "from keras import backend as K\n",
    "\n",
    "def distance_loss(y_pred, y_true):\n",
    "    return K.sqrt(K.mean(K.sum(K.square(y_pred-y_true), axis=-1)))\n",
    "\n",
    "def median_absolute_deviation(y_pred, y_true):\n",
    "    deviation = np.abs(y_pred,y_true)\n",
    "    return np.mean(deviation, axis=0)\n",
    "\n",
    "class LossHistory(keras.callbacks.Callback):\n",
    "    def on_train_begin(self, logs={}):\n",
    "        self.losses = {'batch': [], 'epoch': []}\n",
    "        self.accuracy = {'batch': [], 'epoch': []}\n",
    "        self.val_loss = {'batch': [], 'epoch': []}\n",
    "        self.val_acc = {'batch': [], 'epoch': []}\n",
    "\n",
    "    def on_batch_end(self, batch, logs={}):\n",
    "        self.losses['batch'].append(logs.get('loss'))\n",
    "        self.accuracy['batch'].append(logs.get('acc'))\n",
    "        self.val_loss['batch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['batch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def on_epoch_end(self, batch, logs={}):\n",
    "        self.losses['epoch'].append(logs.get('loss'))\n",
    "        self.accuracy['epoch'].append(logs.get('acc'))\n",
    "        self.val_loss['epoch'].append(logs.get('val_loss'))\n",
    "        self.val_acc['epoch'].append(logs.get('val_acc'))\n",
    "\n",
    "    def loss_plot(self, loss_type):\n",
    "        iters = range(len(self.losses[loss_type]))\n",
    "        plt.figure()\n",
    "        # acc\n",
    "        plt.plot(iters, self.accuracy[loss_type], 'r', label='train acc')\n",
    "        # loss\n",
    "        plt.plot(iters, self.losses[loss_type], 'g', label='train loss')\n",
    "        if loss_type == 'epoch':\n",
    "            # val_acc\n",
    "            plt.plot(iters, self.val_acc[loss_type], 'b', label='val acc')\n",
    "            # val_loss\n",
    "            plt.plot(iters, self.val_loss[loss_type], 'k', label='val loss')\n",
    "        plt.grid(True)\n",
    "        plt.xlabel(loss_type)\n",
    "        plt.ylabel('acc-loss')\n",
    "        plt.legend(loc=\"upper right\")\n",
    "        plt.show()\n",
    "\n",
    "\n",
    "data = pd.read_csv('hwphase2data_update/new_formatted_data2.csv')\n",
    "\n",
    "X = [\n",
    "    np.array([[mr[4:9],\n",
    "              mr[9:14],\n",
    "              mr[14:19],\n",
    "              mr[19:24],\n",
    "              mr[24:29],\n",
    "              mr[29:34]]]).T for mr in data.values\n",
    "]\n",
    "X = np.array(X)\n",
    "y = []\n",
    "zone_number = 0\n",
    "zone_letter = 0\n",
    "for mr in data.values:\n",
    "    lat, lon, zone_number, zone_letter = utm.from_latlon(mr[-4], mr[-5])\n",
    "    y.append([lat, lon])\n",
    "scaler = MinMaxScaler()\n",
    "y = np.array(y)\n",
    "scaler.fit(y)\n",
    "y = scaler.transform(y)\n",
    "\n",
    "def build_model():\n",
    "    m = Sequential()\n",
    "    m.add(Conv2D(32, kernel_size=2, activation='relu', input_shape=(5, 6, 1)))\n",
    "    m.add(Conv2D(16, kernel_size=2, activation='relu'))\n",
    "    m.add(Flatten())\n",
    "    m.add(Dense(1024, activation='relu'))\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(512, activation='relu'))\n",
    "    m.add(Dropout(0.2))\n",
    "    m.add(Dense(256, activation='relu'))\n",
    "    m.add(Dense(2))\n",
    "    r = optimizers.Adam(lr=0.001,decay=0.00001)\n",
    "    m.compile(optimizer=r, loss=distance_loss, metrics=['mse'])\n",
    "\n",
    "    return m\n",
    "\n",
    "\n",
    "history = LossHistory()\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)\n",
    "model = build_model()\n",
    "model.fit(X_train, y_train, validation_data=(X_test, y_test), epochs=500, batch_size=64, callbacks=[history])\n",
    "history.loss_plot('epoch')\n",
    "# data_test = pd.read_csv('new_formatted_.csv')\n",
    "# X_test = [\n",
    "#     np.array([[mr[4:9],\n",
    "#               mr[9:14],\n",
    "#               mr[14:19],\n",
    "#               mr[19:24],\n",
    "#               mr[24:29],\n",
    "#               mr[29:34]]]).T for mr in data_test.values\n",
    "# ]\n",
    "# ------\n",
    "X_test = np.array(X_test)\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = y_pred.reshape(-1,2)\n",
    "y_pred = scaler.inverse_transform(y_pred)\n",
    "print(distance_loss(y_pred,scaler.inverse_transform(y_test)))\n",
    "# ------\n",
    "# y_final = [[utm.to_latlon(i[0], i[1], zone_number=zone_number, zone_letter=zone_letter)[1],\n",
    "#             utm.to_latlon(i[0], i[1], zone_number=zone_number, zone_letter=zone_letter)[0]] for i in y_pred]\n",
    "# y_final = np.array(y_final)\n",
    "# df_pred = pd.DataFrame(data={'Longitude':y_final[:,0], 'Latitude':y_final[:,1]})\n",
    "# df_pred.to_csv('pred1.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "22 23"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
